/**
 * [EXPERIMENTAL] Ollama Adapter
 * Adapts JOS Intentions to Local LLM Prompts
 */
const { apiRequest } = require('../utils/request');

const C = {
    dim: '\x1b[2m',
    reset: '\x1b[0m'
};

async function callOllama(baseUrl, model, messages) {
    // Ensure URL ends with /api/chat
    const endpoint = baseUrl.endsWith('/api/chat') ? baseUrl : `${baseUrl.replace(/\/$/, '')}/api/chat`;

    console.log(`${C.dim}Connecting to Ollama at ${endpoint}...${C.reset}`);

    return apiRequest(endpoint, 'POST', {
        model: model || 'llama3', // Default to llama3 if not specified
        messages: messages,
        stream: false,
        format: 'json' // Force JSON mode for structure
    });
}

module.exports = {
    type: 'ollama',
    experimental: true,

    async optimize(artifact, options, providerUrl, model) {
        const prompt = `You are an expert prompt engineer specializing in JOS (JSON Orchestration Spec).
        Your goal is to optimize the PROMPTS inside the following JOS artifact.
        
        GOALS: ${options.optimization_goals.join(', ')}
        
        INPUT ARTIFACT:
        ${JSON.stringify(artifact, null, 2)}
        
        INSTRUCTIONS:
        1. Analyze the 'intention' and 'tasks'.
        2. Rewrite task descriptions to be more precise, using Chain-of-Thought or clear directives.
        3. Do NOT change the structure or keys. Only text content.
        4. Return the COMPLETE logical JSON of the optimized artifact.
        `;

        const res = await callOllama(providerUrl, model, [{ role: 'user', content: prompt }]);

        if (res.status !== 200) throw new Error(`Ollama Error: ${res.status} ${JSON.stringify(res.data)}`);

        const optimizedArtifact = typeof res.data.message.content === 'string'
            ? JSON.parse(res.data.message.content)
            : res.data.message.content;

        // Mock quality score for local execution
        return {
            optimized_artifact: optimizedArtifact,
            quality_score: { before: 0.5, after: 0.9 },
            changes: [{ field: 'tasks', original: '...', optimized: '...', reason: 'Ollama Optimization' }]
        };
    },

    async validate(artifact, providerUrl, model) {
        const prompt = `You are a QA Validator for JOS Artifacts.
        Analyze the following artifact for logical consistency, missing context, or vague prompts.
        
        ARTIFACT:
        ${JSON.stringify(artifact, null, 2)}
        
        Return a JSON object with:
        - valid (boolean)
        - quality_score (0.0 to 1.0)
        - issues (array of objects { field, message, severity })
        - suggestions (array of objects { field, suggestion })
        `;

        const res = await callOllama(providerUrl, model, [{ role: 'user', content: prompt }]);
        if (res.status !== 200) throw new Error(`Ollama Error: ${res.status}`);

        return typeof res.data.message.content === 'string'
            ? JSON.parse(res.data.message.content)
            : res.data.message.content;
    },

    async generate(intention, options, providerUrl, model) {
        const prompt = `You are a JOS Architect. Generate a valid .jos JSON artifact based on this user intention.
        
        INTENTION: "${intention}"
        
        REQUIREMENTS:
        - Type: ${options.type || 'task'}
        - Format: JOS v0.0.7 (JSON)
        - Must include 'intention', 'tasks', and 'orchestration'.
        
        Return ONLY the JSON.
        `;

        const res = await callOllama(providerUrl, model, [{ role: 'user', content: prompt }]);
        if (res.status !== 200) throw new Error(`Ollama Error: ${res.status}`);

        const artifact = typeof res.data.message.content === 'string'
            ? JSON.parse(res.data.message.content)
            : res.data.message.content;

        return {
            confidence: 0.85,
            artifact: artifact,
            assumptions: ['Generated by Local Ollama']
        };
    },

    async execute(artifact, providerUrl, model) {
        // MAGIC JOSFOXAI PROMPT WRAPPER
        const systemPrompt = `[SYSTEM]
You are an Intention-Native Agent powered by JOSFOXAI.
MAGIC_KEY: JOSFOX_ALPHA_V1

You are executing the following JOS Artifact.
Strictly adhere to the 'orchestration' flow and 'requirements'.

ARTIFACT:
${JSON.stringify(artifact, null, 2)}
`;

        const userPrompt = `Execute the intention defined in the artifact. Report your status.`;

        const res = await callOllama(providerUrl, model, [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: userPrompt }
        ]);

        if (res.status !== 200) throw new Error(`Ollama Error: ${res.status}`);

        // For non-native adapters, the result is text/chat, which we wrap in a JOS result structure
        return {
            status: 'completed',
            output: typeof res.data.message.content === 'string' ? res.data.message.content : JSON.stringify(res.data.message.content),
            provider: 'ollama'
        };
    }
};
